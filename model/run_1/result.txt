calculation mAP (mean average precision)...
 Detection layer: 30 - type = 28 
 Detection layer: 37 - type = 28 

 detections_count = 985, unique_truth_count = 216  
 rank = 0 of ranks = 985 
 rank = 100 of ranks = 985 
 rank = 200 of ranks = 985 
 rank = 300 of ranks = 985 
 rank = 400 of ranks = 985 
 rank = 500 of ranks = 985 
 rank = 600 of ranks = 985 
 rank = 700 of ranks = 985 
 rank = 800 of ranks = 985 
 rank = 900 of ranks = 985 
class_id = 0, name = Mensa, ap = 78.01%   	 (TP = 17, FP = 3) 
class_id = 1, name = AKK, ap = 84.36%   	 (TP = 7, FP = 2) 
class_id = 2, name = Audimax, ap = 78.08%   	 (TP = 9, FP = 3) 
class_id = 3, name = Neue Bib, ap = 51.23%   	 (TP = 8, FP = 4) 
class_id = 4, name = Alte Bib, ap = 78.62%   	 (TP = 19, FP = 1) 
class_id = 5, name = Studierendenwerk, ap = 61.42%   	 (TP = 5, FP = 0) 
class_id = 6, name = Lernzentrum, ap = 92.89%   	 (TP = 10, FP = 0) 
class_id = 7, name = Mathebau, ap = 95.45%   	 (TP = 11, FP = 1) 
class_id = 8, name = Harber-Bosch-Reaktor, ap = 100.00%   	 (TP = 14, FP = 0) 
class_id = 9, name = Statue am Ehrenhof, ap = 100.00%   	 (TP = 12, FP = 1) 
class_id = 10, name = Heinrich-Hertz-Denkmal, ap = 81.41%   	 (TP = 9, FP = 1) 
class_id = 11, name = Kolben, ap = 73.06%   	 (TP = 9, FP = 1) 
class_id = 12, name = Waermeflasche, ap = 93.14%   	 (TP = 7, FP = 2) 
class_id = 13, name = Gruenderschmiede, ap = 87.17%   	 (TP = 9, FP = 0) 

 for conf_thresh = 0.25, precision = 0.88, recall = 0.68, F1-score = 0.77 
 for conf_thresh = 0.25, TP = 146, FP = 19, FN = 70, average IoU = 65.09 % 

 IoU threshold = 50 %, used Area-Under-Curve for each unique Recall 
 mean average precision (mAP@0.50) = 0.824886, or 82.49 %